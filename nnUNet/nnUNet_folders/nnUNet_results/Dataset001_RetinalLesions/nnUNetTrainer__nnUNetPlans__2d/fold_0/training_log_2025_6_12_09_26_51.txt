
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-06-12 09:26:52.616660: Using torch.compile... 
2025-06-12 09:26:53.686858: do_dummy_2d_data_aug: False 
2025-06-12 09:26:53.690811: Using splits from existing split file: /home/ubuntu/nnUNet/preprocessed_version/nnUNet_preprocessed/Dataset001_RetinalLesions/splits_final.json 
2025-06-12 09:26:53.691761: The split file contains 5 splits. 
2025-06-12 09:26:53.691824: Desired fold for training: 0 
2025-06-12 09:26:53.691853: This split has 1136 training and 285 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 16, 'patch_size': [448, 448], 'median_image_size_in_voxels': [423.0, 440.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_RetinalLesions', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 423, 440], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 128.96560668945312, 'median': 126.0, 'min': 0.0, 'percentile_00_5': 34.0, 'percentile_99_5': 253.0, 'std': 46.385581970214844}, '1': {'max': 255.0, 'mean': 86.79081726074219, 'median': 84.0, 'min': 0.0, 'percentile_00_5': 22.0, 'percentile_99_5': 186.0, 'std': 33.978126525878906}, '2': {'max': 248.0, 'mean': 58.95289611816406, 'median': 56.0, 'min': 0.0, 'percentile_00_5': 1.0, 'percentile_99_5': 153.0, 'std': 30.95760154724121}}} 
 
2025-06-12 09:26:56.212339: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-06-12 09:26:56.221227:  
2025-06-12 09:26:56.221425: Epoch 0 
2025-06-12 09:26:56.221613: Current learning rate: 0.01 
2025-06-12 09:27:49.148441: train_loss 0.1312 
2025-06-12 09:27:49.148883: val_loss 0.0793 
2025-06-12 09:27:49.149071: Pseudo dice [np.float32(0.0)] 
2025-06-12 09:27:49.149180: Epoch time: 52.93 s 
2025-06-12 09:27:49.149357: Yayy! New best EMA pseudo Dice: 0.0 
2025-06-12 09:27:50.384590:  
2025-06-12 09:27:50.384873: Epoch 1 
2025-06-12 09:27:50.385043: Current learning rate: 0.00999 
2025-06-12 09:28:30.433361: train_loss 0.0935 
2025-06-12 09:28:30.433659: val_loss 0.0759 
2025-06-12 09:28:30.433741: Pseudo dice [np.float32(0.0)] 
2025-06-12 09:28:30.433826: Epoch time: 40.05 s 
2025-06-12 09:28:31.469206:  
2025-06-12 09:28:31.469429: Epoch 2 
2025-06-12 09:28:31.469684: Current learning rate: 0.00998 
2025-06-12 09:29:11.861272: train_loss 0.0765 
2025-06-12 09:29:11.861632: val_loss 0.0396 
2025-06-12 09:29:11.861781: Pseudo dice [np.float32(0.0)] 
2025-06-12 09:29:11.861886: Epoch time: 40.39 s 
2025-06-12 09:29:12.929146:  
2025-06-12 09:29:12.929385: Epoch 3 
2025-06-12 09:29:12.929871: Current learning rate: 0.00997 
2025-06-12 09:29:53.210186: train_loss -0.0116 
2025-06-12 09:29:53.210478: val_loss -0.1741 
2025-06-12 09:29:53.210684: Pseudo dice [np.float32(0.3692)] 
2025-06-12 09:29:53.210789: Epoch time: 40.28 s 
2025-06-12 09:29:53.210850: Yayy! New best EMA pseudo Dice: 0.03689999878406525 
2025-06-12 09:29:54.728457:  
2025-06-12 09:29:54.728878: Epoch 4 
2025-06-12 09:29:54.729049: Current learning rate: 0.00996 
2025-06-12 09:30:35.007337: train_loss -0.1206 
2025-06-12 09:30:35.007566: val_loss -0.2145 
2025-06-12 09:30:35.007630: Pseudo dice [np.float32(0.3889)] 
2025-06-12 09:30:35.007699: Epoch time: 40.28 s 
2025-06-12 09:30:35.007745: Yayy! New best EMA pseudo Dice: 0.07209999859333038 
2025-06-12 09:30:36.541970:  
2025-06-12 09:30:36.542111: Epoch 5 
2025-06-12 09:30:36.542312: Current learning rate: 0.00995 
2025-06-12 09:31:16.836933: train_loss -0.1867 
2025-06-12 09:31:16.837178: val_loss -0.2478 
2025-06-12 09:31:16.837276: Pseudo dice [np.float32(0.4399)] 
2025-06-12 09:31:16.837350: Epoch time: 40.3 s 
2025-06-12 09:31:16.837399: Yayy! New best EMA pseudo Dice: 0.10890000313520432 
2025-06-12 09:31:18.331473:  
2025-06-12 09:31:18.331970: Epoch 6 
2025-06-12 09:31:18.332163: Current learning rate: 0.00995 
2025-06-12 09:31:58.628009: train_loss -0.2717 
2025-06-12 09:31:58.628246: val_loss -0.2403 
2025-06-12 09:31:58.628312: Pseudo dice [np.float32(0.4433)] 
2025-06-12 09:31:58.628382: Epoch time: 40.3 s 
2025-06-12 09:31:58.628501: Yayy! New best EMA pseudo Dice: 0.14229999482631683 
2025-06-12 09:32:00.146625:  
2025-06-12 09:32:00.146797: Epoch 7 
2025-06-12 09:32:00.146911: Current learning rate: 0.00994 
2025-06-12 09:32:40.406933: train_loss -0.3212 
2025-06-12 09:32:40.407277: val_loss -0.364 
2025-06-12 09:32:40.407349: Pseudo dice [np.float32(0.53)] 
2025-06-12 09:32:40.407419: Epoch time: 40.26 s 
2025-06-12 09:32:40.407468: Yayy! New best EMA pseudo Dice: 0.181099995970726 
2025-06-12 09:32:41.913125:  
2025-06-12 09:32:41.913584: Epoch 8 
2025-06-12 09:32:41.913677: Current learning rate: 0.00993 
2025-06-12 09:33:22.177266: train_loss -0.3523 
2025-06-12 09:33:22.177464: val_loss -0.4023 
2025-06-12 09:33:22.177527: Pseudo dice [np.float32(0.5515)] 
2025-06-12 09:33:22.177594: Epoch time: 40.27 s 
2025-06-12 09:33:22.177643: Yayy! New best EMA pseudo Dice: 0.21809999644756317 
2025-06-12 09:33:23.628645:  
2025-06-12 09:33:23.628942: Epoch 9 
2025-06-12 09:33:23.629076: Current learning rate: 0.00992 
2025-06-12 09:34:03.791456: train_loss -0.4032 
2025-06-12 09:34:03.791818: val_loss -0.3988 
2025-06-12 09:34:03.791892: Pseudo dice [np.float32(0.5394)] 
2025-06-12 09:34:03.791978: Epoch time: 40.16 s 
2025-06-12 09:34:03.792029: Yayy! New best EMA pseudo Dice: 0.25029999017715454 
2025-06-12 09:34:05.228369:  
2025-06-12 09:34:05.228611: Epoch 10 
2025-06-12 09:34:05.228774: Current learning rate: 0.00991 
2025-06-12 09:34:45.400282: train_loss -0.4135 
2025-06-12 09:34:45.400543: val_loss -0.3995 
2025-06-12 09:34:45.400623: Pseudo dice [np.float32(0.5543)] 
2025-06-12 09:34:45.400689: Epoch time: 40.17 s 
2025-06-12 09:34:45.400739: Yayy! New best EMA pseudo Dice: 0.2806999981403351 
2025-06-12 09:34:47.144934:  
2025-06-12 09:34:47.145144: Epoch 11 
2025-06-12 09:34:47.145261: Current learning rate: 0.0099 
2025-06-12 09:35:27.290990: train_loss -0.4349 
2025-06-12 09:35:27.291538: val_loss -0.4245 
2025-06-12 09:35:27.291629: Pseudo dice [np.float32(0.5788)] 
2025-06-12 09:35:27.291720: Epoch time: 40.15 s 
2025-06-12 09:35:27.291777: Yayy! New best EMA pseudo Dice: 0.31049999594688416 
2025-06-12 09:35:28.705907:  
2025-06-12 09:35:28.706349: Epoch 12 
2025-06-12 09:35:28.706492: Current learning rate: 0.00989 
2025-06-12 09:36:09.021480: train_loss -0.4366 
2025-06-12 09:36:09.021753: val_loss -0.3901 
2025-06-12 09:36:09.021819: Pseudo dice [np.float32(0.5491)] 
2025-06-12 09:36:09.021895: Epoch time: 40.32 s 
2025-06-12 09:36:09.021955: Yayy! New best EMA pseudo Dice: 0.3343000113964081 
2025-06-12 09:36:10.462047:  
2025-06-12 09:36:10.462364: Epoch 13 
2025-06-12 09:36:10.462486: Current learning rate: 0.00988 
2025-06-12 09:36:50.640119: train_loss -0.4409 
2025-06-12 09:36:50.640332: val_loss -0.4488 
2025-06-12 09:36:50.640394: Pseudo dice [np.float32(0.5854)] 
2025-06-12 09:36:50.640494: Epoch time: 40.18 s 
2025-06-12 09:36:50.640544: Yayy! New best EMA pseudo Dice: 0.3594000041484833 
2025-06-12 09:36:52.099690:  
2025-06-12 09:36:52.099942: Epoch 14 
2025-06-12 09:36:52.100071: Current learning rate: 0.00987 
2025-06-12 09:37:32.284664: train_loss -0.4553 
2025-06-12 09:37:32.284883: val_loss -0.4301 
2025-06-12 09:37:32.284951: Pseudo dice [np.float32(0.5856)] 
2025-06-12 09:37:32.285038: Epoch time: 40.19 s 
2025-06-12 09:37:32.285302: Yayy! New best EMA pseudo Dice: 0.382099986076355 
2025-06-12 09:37:33.748216:  
2025-06-12 09:37:33.748450: Epoch 15 
2025-06-12 09:37:33.748631: Current learning rate: 0.00986 
2025-06-12 09:38:14.007750: train_loss -0.478 
2025-06-12 09:38:14.007958: val_loss -0.4086 
2025-06-12 09:38:14.008054: Pseudo dice [np.float32(0.5729)] 
2025-06-12 09:38:14.008157: Epoch time: 40.26 s 
2025-06-12 09:38:14.008247: Yayy! New best EMA pseudo Dice: 0.4011000096797943 
2025-06-12 09:38:15.475786:  
2025-06-12 09:38:15.476288: Epoch 16 
2025-06-12 09:38:15.476463: Current learning rate: 0.00986 
2025-06-12 09:38:55.640546: train_loss -0.4805 
2025-06-12 09:38:55.640768: val_loss -0.4774 
2025-06-12 09:38:55.640839: Pseudo dice [np.float32(0.6153)] 
2025-06-12 09:38:55.640909: Epoch time: 40.17 s 
2025-06-12 09:38:55.640965: Yayy! New best EMA pseudo Dice: 0.42260000109672546 
2025-06-12 09:38:57.110872:  
2025-06-12 09:38:57.110992: Epoch 17 
2025-06-12 09:38:57.111079: Current learning rate: 0.00985 
2025-06-12 09:39:37.334152: train_loss -0.4825 
2025-06-12 09:39:37.334389: val_loss -0.4782 
2025-06-12 09:39:37.334493: Pseudo dice [np.float32(0.6126)] 
2025-06-12 09:39:37.334627: Epoch time: 40.22 s 
2025-06-12 09:39:37.334807: Yayy! New best EMA pseudo Dice: 0.4415999948978424 
2025-06-12 09:39:38.894398:  
2025-06-12 09:39:38.894675: Epoch 18 
2025-06-12 09:39:38.894862: Current learning rate: 0.00984 
2025-06-12 09:40:19.119526: train_loss -0.4909 
2025-06-12 09:40:19.119766: val_loss -0.4467 
2025-06-12 09:40:19.119878: Pseudo dice [np.float32(0.5792)] 
2025-06-12 09:40:19.120017: Epoch time: 40.23 s 
2025-06-12 09:40:19.120159: Yayy! New best EMA pseudo Dice: 0.4553000032901764 
2025-06-12 09:40:20.593429:  
2025-06-12 09:40:20.593681: Epoch 19 
2025-06-12 09:40:20.593820: Current learning rate: 0.00983 
2025-06-12 09:41:00.772958: train_loss -0.4942 
2025-06-12 09:41:00.773274: val_loss -0.4785 
2025-06-12 09:41:00.773345: Pseudo dice [np.float32(0.6199)] 
2025-06-12 09:41:00.773410: Epoch time: 40.18 s 
2025-06-12 09:41:00.773474: Yayy! New best EMA pseudo Dice: 0.4717999994754791 
2025-06-12 09:41:02.276268:  
2025-06-12 09:41:02.276458: Epoch 20 
2025-06-12 09:41:02.276642: Current learning rate: 0.00982 
2025-06-12 09:41:42.547451: train_loss -0.4964 
2025-06-12 09:41:42.547628: val_loss -0.4385 
2025-06-12 09:41:42.547796: Pseudo dice [np.float32(0.5743)] 
2025-06-12 09:41:42.547896: Epoch time: 40.27 s 
2025-06-12 09:41:42.548167: Yayy! New best EMA pseudo Dice: 0.4819999933242798 
2025-06-12 09:41:44.017891:  
2025-06-12 09:41:44.018006: Epoch 21 
2025-06-12 09:41:44.018087: Current learning rate: 0.00981 
2025-06-12 09:42:24.182979: train_loss -0.4898 
2025-06-12 09:42:24.183368: val_loss -0.4724 
2025-06-12 09:42:24.183456: Pseudo dice [np.float32(0.5984)] 
2025-06-12 09:42:24.183531: Epoch time: 40.17 s 
2025-06-12 09:42:24.183591: Yayy! New best EMA pseudo Dice: 0.4936999976634979 
2025-06-12 09:42:25.949576:  
2025-06-12 09:42:25.949707: Epoch 22 
2025-06-12 09:42:25.950371: Current learning rate: 0.0098 
2025-06-12 09:43:06.317818: train_loss -0.5217 
2025-06-12 09:43:06.318089: val_loss -0.4465 
2025-06-12 09:43:06.318154: Pseudo dice [np.float32(0.5832)] 
2025-06-12 09:43:06.318263: Epoch time: 40.37 s 
2025-06-12 09:43:06.318321: Yayy! New best EMA pseudo Dice: 0.5026000142097473 
2025-06-12 09:43:07.745410:  
2025-06-12 09:43:07.745532: Epoch 23 
2025-06-12 09:43:07.745614: Current learning rate: 0.00979 
2025-06-12 09:43:47.956740: train_loss -0.4884 
2025-06-12 09:43:47.956979: val_loss -0.4533 
2025-06-12 09:43:47.957067: Pseudo dice [np.float32(0.5807)] 
2025-06-12 09:43:47.957268: Epoch time: 40.21 s 
2025-06-12 09:43:47.957339: Yayy! New best EMA pseudo Dice: 0.5103999972343445 
2025-06-12 09:43:49.378828:  
2025-06-12 09:43:49.379126: Epoch 24 
2025-06-12 09:43:49.379237: Current learning rate: 0.00978 
2025-06-12 09:44:29.684315: train_loss -0.52 
2025-06-12 09:44:29.684517: val_loss -0.4432 
2025-06-12 09:44:29.684595: Pseudo dice [np.float32(0.5819)] 
2025-06-12 09:44:29.684690: Epoch time: 40.31 s 
2025-06-12 09:44:29.684757: Yayy! New best EMA pseudo Dice: 0.5175999999046326 
2025-06-12 09:44:31.143935:  
2025-06-12 09:44:31.144176: Epoch 25 
2025-06-12 09:44:31.144407: Current learning rate: 0.00977 
2025-06-12 09:45:11.411455: train_loss -0.5225 
2025-06-12 09:45:11.411656: val_loss -0.4324 
2025-06-12 09:45:11.411722: Pseudo dice [np.float32(0.5713)] 
2025-06-12 09:45:11.411786: Epoch time: 40.27 s 
2025-06-12 09:45:11.411833: Yayy! New best EMA pseudo Dice: 0.5230000019073486 
2025-06-12 09:45:12.855800:  
2025-06-12 09:45:12.856147: Epoch 26 
2025-06-12 09:45:12.856429: Current learning rate: 0.00977 
2025-06-12 09:45:53.028440: train_loss -0.5198 
2025-06-12 09:45:53.028780: val_loss -0.4844 
2025-06-12 09:45:53.028848: Pseudo dice [np.float32(0.6084)] 
2025-06-12 09:45:53.028914: Epoch time: 40.17 s 
2025-06-12 09:45:53.028967: Yayy! New best EMA pseudo Dice: 0.531499981880188 
2025-06-12 09:45:54.460860:  
2025-06-12 09:45:54.460977: Epoch 27 
2025-06-12 09:45:54.461054: Current learning rate: 0.00976 
2025-06-12 09:46:34.751387: train_loss -0.5261 
2025-06-12 09:46:34.751655: val_loss -0.4895 
2025-06-12 09:46:34.751724: Pseudo dice [np.float32(0.6194)] 
2025-06-12 09:46:34.751792: Epoch time: 40.29 s 
2025-06-12 09:46:34.751842: Yayy! New best EMA pseudo Dice: 0.5403000116348267 
2025-06-12 09:46:36.204257:  
2025-06-12 09:46:36.204434: Epoch 28 
2025-06-12 09:46:36.204541: Current learning rate: 0.00975 
2025-06-12 09:47:16.475297: train_loss -0.5423 
2025-06-12 09:47:16.475530: val_loss -0.4919 
2025-06-12 09:47:16.475684: Pseudo dice [np.float32(0.6184)] 
2025-06-12 09:47:16.475917: Epoch time: 40.27 s 
2025-06-12 09:47:16.475990: Yayy! New best EMA pseudo Dice: 0.5480999946594238 
2025-06-12 09:47:17.915707:  
2025-06-12 09:47:17.915829: Epoch 29 
2025-06-12 09:47:17.915923: Current learning rate: 0.00974 
2025-06-12 09:47:58.118500: train_loss -0.5315 
2025-06-12 09:47:58.118839: val_loss -0.4961 
2025-06-12 09:47:58.118914: Pseudo dice [np.float32(0.6184)] 
2025-06-12 09:47:58.118991: Epoch time: 40.2 s 
2025-06-12 09:47:58.119123: Yayy! New best EMA pseudo Dice: 0.5551000237464905 
2025-06-12 09:47:59.573732:  
2025-06-12 09:47:59.573847: Epoch 30 
2025-06-12 09:47:59.573934: Current learning rate: 0.00973 
2025-06-12 09:48:39.760401: train_loss -0.5373 
2025-06-12 09:48:39.760621: val_loss -0.5068 
2025-06-12 09:48:39.760694: Pseudo dice [np.float32(0.6301)] 
2025-06-12 09:48:39.760758: Epoch time: 40.19 s 
2025-06-12 09:48:39.760821: Yayy! New best EMA pseudo Dice: 0.5626000165939331 
2025-06-12 09:48:41.289879:  
2025-06-12 09:48:41.290246: Epoch 31 
2025-06-12 09:48:41.290463: Current learning rate: 0.00972 
2025-06-12 09:49:21.543916: train_loss -0.5315 
2025-06-12 09:49:21.544322: val_loss -0.4839 
2025-06-12 09:49:21.544503: Pseudo dice [np.float32(0.6198)] 
2025-06-12 09:49:21.544574: Epoch time: 40.26 s 
2025-06-12 09:49:21.544624: Yayy! New best EMA pseudo Dice: 0.5683000087738037 
2025-06-12 09:49:23.025095:  
2025-06-12 09:49:23.025228: Epoch 32 
2025-06-12 09:49:23.025496: Current learning rate: 0.00971 
2025-06-12 09:50:03.429615: train_loss -0.5319 
2025-06-12 09:50:03.430104: val_loss -0.5073 
2025-06-12 09:50:03.430326: Pseudo dice [np.float32(0.6367)] 
2025-06-12 09:50:03.430590: Epoch time: 40.41 s 
2025-06-12 09:50:03.430793: Yayy! New best EMA pseudo Dice: 0.5752000212669373 
2025-06-12 09:50:04.905376:  
2025-06-12 09:50:04.905519: Epoch 33 
2025-06-12 09:50:04.905720: Current learning rate: 0.0097 
2025-06-12 09:50:45.262746: train_loss -0.5473 
2025-06-12 09:50:45.263273: val_loss -0.4891 
2025-06-12 09:50:45.263534: Pseudo dice [np.float32(0.6168)] 
2025-06-12 09:50:45.263638: Epoch time: 40.36 s 
2025-06-12 09:50:45.263711: Yayy! New best EMA pseudo Dice: 0.5792999863624573 
2025-06-12 09:50:47.095587:  
2025-06-12 09:50:47.095826: Epoch 34 
2025-06-12 09:50:47.096026: Current learning rate: 0.00969 
2025-06-12 09:51:27.469648: train_loss -0.5593 
2025-06-12 09:51:27.469832: val_loss -0.5191 
2025-06-12 09:51:27.469894: Pseudo dice [np.float32(0.6433)] 
2025-06-12 09:51:27.469960: Epoch time: 40.38 s 
2025-06-12 09:51:27.470019: Yayy! New best EMA pseudo Dice: 0.5856999754905701 
2025-06-12 09:51:28.948039:  
2025-06-12 09:51:28.948179: Epoch 35 
2025-06-12 09:51:28.948433: Current learning rate: 0.00968 
2025-06-12 09:52:09.241617: train_loss -0.5549 
2025-06-12 09:52:09.241836: val_loss -0.4334 
2025-06-12 09:52:09.241901: Pseudo dice [np.float32(0.5729)] 
2025-06-12 09:52:09.241968: Epoch time: 40.29 s 
2025-06-12 09:52:10.334960:  
2025-06-12 09:52:10.335134: Epoch 36 
2025-06-12 09:52:10.335479: Current learning rate: 0.00968 
2025-06-12 09:52:50.627878: train_loss -0.5481 
2025-06-12 09:52:50.628113: val_loss -0.4996 
2025-06-12 09:52:50.628188: Pseudo dice [np.float32(0.6271)] 
2025-06-12 09:52:50.628303: Epoch time: 40.29 s 
2025-06-12 09:52:50.628354: Yayy! New best EMA pseudo Dice: 0.588699996471405 
2025-06-12 09:52:52.175751:  
2025-06-12 09:52:52.176143: Epoch 37 
2025-06-12 09:52:52.176405: Current learning rate: 0.00967 
2025-06-12 09:53:32.456990: train_loss -0.563 
2025-06-12 09:53:32.457297: val_loss -0.476 
2025-06-12 09:53:32.457473: Pseudo dice [np.float32(0.5879)] 
2025-06-12 09:53:32.457613: Epoch time: 40.28 s 
2025-06-12 09:53:33.552067:  
2025-06-12 09:53:33.552406: Epoch 38 
2025-06-12 09:53:33.552757: Current learning rate: 0.00966 
2025-06-12 09:54:13.898728: train_loss -0.5591 
2025-06-12 09:54:13.899065: val_loss -0.468 
2025-06-12 09:54:13.899148: Pseudo dice [np.float32(0.598)] 
2025-06-12 09:54:13.899230: Epoch time: 40.35 s 
2025-06-12 09:54:13.899354: Yayy! New best EMA pseudo Dice: 0.5896000266075134 
2025-06-12 09:54:15.439191:  
2025-06-12 09:54:15.439540: Epoch 39 
2025-06-12 09:54:15.439914: Current learning rate: 0.00965 
2025-06-12 09:54:55.758548: train_loss -0.5765 
2025-06-12 09:54:55.758800: val_loss -0.5088 
2025-06-12 09:54:55.758876: Pseudo dice [np.float32(0.6318)] 
2025-06-12 09:54:55.759139: Epoch time: 40.32 s 
2025-06-12 09:54:55.759198: Yayy! New best EMA pseudo Dice: 0.5938000082969666 
2025-06-12 09:54:57.322308:  
2025-06-12 09:54:57.322701: Epoch 40 
2025-06-12 09:54:57.322956: Current learning rate: 0.00964 
2025-06-12 09:55:37.551373: train_loss -0.559 
2025-06-12 09:55:37.551738: val_loss -0.5068 
2025-06-12 09:55:37.551808: Pseudo dice [np.float32(0.6154)] 
2025-06-12 09:55:37.551883: Epoch time: 40.23 s 
2025-06-12 09:55:37.551932: Yayy! New best EMA pseudo Dice: 0.5960000157356262 
2025-06-12 09:55:39.096392:  
2025-06-12 09:55:39.096644: Epoch 41 
2025-06-12 09:55:39.096866: Current learning rate: 0.00963 
2025-06-12 09:56:19.439098: train_loss -0.5673 
2025-06-12 09:56:19.439366: val_loss -0.5107 
2025-06-12 09:56:19.439428: Pseudo dice [np.float32(0.6363)] 
2025-06-12 09:56:19.439509: Epoch time: 40.34 s 
2025-06-12 09:56:19.439574: Yayy! New best EMA pseudo Dice: 0.6000000238418579 
2025-06-12 09:56:20.948400:  
2025-06-12 09:56:20.948678: Epoch 42 
2025-06-12 09:56:20.948771: Current learning rate: 0.00962 
2025-06-12 09:57:01.164783: train_loss -0.5679 
2025-06-12 09:57:01.165050: val_loss -0.4954 
2025-06-12 09:57:01.165137: Pseudo dice [np.float32(0.6139)] 
2025-06-12 09:57:01.165231: Epoch time: 40.22 s 
2025-06-12 09:57:01.165303: Yayy! New best EMA pseudo Dice: 0.6014000177383423 
2025-06-12 09:57:02.693645:  
2025-06-12 09:57:02.693924: Epoch 43 
2025-06-12 09:57:02.694077: Current learning rate: 0.00961 
2025-06-12 09:57:43.011300: train_loss -0.5911 
2025-06-12 09:57:43.011749: val_loss -0.5129 
2025-06-12 09:57:43.011831: Pseudo dice [np.float32(0.6418)] 
2025-06-12 09:57:43.011920: Epoch time: 40.32 s 
2025-06-12 09:57:43.011978: Yayy! New best EMA pseudo Dice: 0.605400025844574 
2025-06-12 09:57:44.523086:  
2025-06-12 09:57:44.523354: Epoch 44 
2025-06-12 09:57:44.523508: Current learning rate: 0.0096 
2025-06-12 09:58:24.736468: train_loss -0.5727 
2025-06-12 09:58:24.736711: val_loss -0.4907 
2025-06-12 09:58:24.736779: Pseudo dice [np.float32(0.6047)] 
2025-06-12 09:58:24.736848: Epoch time: 40.21 s 
2025-06-12 09:58:26.301123:  
2025-06-12 09:58:26.301474: Epoch 45 
2025-06-12 09:58:26.301650: Current learning rate: 0.00959 
2025-06-12 09:59:06.568402: train_loss -0.5898 
2025-06-12 09:59:06.568636: val_loss -0.4941 
2025-06-12 09:59:06.568710: Pseudo dice [np.float32(0.6201)] 
2025-06-12 09:59:06.568779: Epoch time: 40.27 s 
2025-06-12 09:59:06.568834: Yayy! New best EMA pseudo Dice: 0.6068000197410583 
2025-06-12 09:59:08.099824:  
2025-06-12 09:59:08.100219: Epoch 46 
2025-06-12 09:59:08.100441: Current learning rate: 0.00959 
2025-06-12 09:59:48.448959: train_loss -0.5793 
2025-06-12 09:59:48.449212: val_loss -0.5093 
2025-06-12 09:59:48.449286: Pseudo dice [np.float32(0.6274)] 
2025-06-12 09:59:48.449360: Epoch time: 40.35 s 
2025-06-12 09:59:48.449420: Yayy! New best EMA pseudo Dice: 0.6089000105857849 
2025-06-12 09:59:49.948928:  
2025-06-12 09:59:49.949242: Epoch 47 
2025-06-12 09:59:49.949346: Current learning rate: 0.00958 
2025-06-12 10:00:30.315945: train_loss -0.5891 
2025-06-12 10:00:30.316207: val_loss -0.5234 
2025-06-12 10:00:30.316290: Pseudo dice [np.float32(0.6426)] 
2025-06-12 10:00:30.316366: Epoch time: 40.37 s 
2025-06-12 10:00:30.316438: Yayy! New best EMA pseudo Dice: 0.6122000217437744 
2025-06-12 10:00:31.790807:  
2025-06-12 10:00:31.790941: Epoch 48 
2025-06-12 10:00:31.791029: Current learning rate: 0.00957 
2025-06-12 10:01:12.174329: train_loss -0.5936 
2025-06-12 10:01:12.174620: val_loss -0.5054 
2025-06-12 10:01:12.174955: Pseudo dice [np.float32(0.6372)] 
2025-06-12 10:01:12.175034: Epoch time: 40.38 s 
2025-06-12 10:01:12.175088: Yayy! New best EMA pseudo Dice: 0.6147000193595886 
2025-06-12 10:01:13.646865:  
2025-06-12 10:01:13.647051: Epoch 49 
2025-06-12 10:01:13.647235: Current learning rate: 0.00956 
2025-06-12 10:01:53.974566: train_loss -0.5653 
2025-06-12 10:01:53.974774: val_loss -0.5138 
2025-06-12 10:01:53.974843: Pseudo dice [np.float32(0.6328)] 
2025-06-12 10:01:53.974912: Epoch time: 40.33 s 
2025-06-12 10:01:54.311764: Yayy! New best EMA pseudo Dice: 0.6165000200271606 
2025-06-12 10:01:56.198876:  
2025-06-12 10:01:56.199079: Epoch 50 
2025-06-12 10:01:56.199259: Current learning rate: 0.00955 
2025-06-12 10:02:36.480181: train_loss -0.5979 
2025-06-12 10:02:36.480532: val_loss -0.4806 
2025-06-12 10:02:36.480800: Pseudo dice [np.float32(0.6174)] 
2025-06-12 10:02:36.480882: Epoch time: 40.28 s 
2025-06-12 10:02:36.480938: Yayy! New best EMA pseudo Dice: 0.616599977016449 
2025-06-12 10:02:37.998260:  
2025-06-12 10:02:37.998501: Epoch 51 
2025-06-12 10:02:37.998825: Current learning rate: 0.00954 
2025-06-12 10:03:18.367288: train_loss -0.6 
2025-06-12 10:03:18.367597: val_loss -0.5169 
2025-06-12 10:03:18.367672: Pseudo dice [np.float32(0.6385)] 
2025-06-12 10:03:18.368050: Epoch time: 40.37 s 
2025-06-12 10:03:18.368137: Yayy! New best EMA pseudo Dice: 0.6187999844551086 
2025-06-12 10:03:20.331146:  
2025-06-12 10:03:20.331445: Epoch 52 
2025-06-12 10:03:20.331661: Current learning rate: 0.00953 
2025-06-12 10:04:00.559052: train_loss -0.6042 
2025-06-12 10:04:00.559396: val_loss -0.4647 
2025-06-12 10:04:00.559505: Pseudo dice [np.float32(0.5958)] 
2025-06-12 10:04:00.559588: Epoch time: 40.23 s 
2025-06-12 10:04:01.602239:  
2025-06-12 10:04:01.602358: Epoch 53 
2025-06-12 10:04:01.602456: Current learning rate: 0.00952 
2025-06-12 10:04:41.860433: train_loss -0.6079 
2025-06-12 10:04:41.860647: val_loss -0.4823 
2025-06-12 10:04:41.860724: Pseudo dice [np.float32(0.6163)] 
2025-06-12 10:04:41.860801: Epoch time: 40.26 s 
2025-06-12 10:04:42.913454:  
2025-06-12 10:04:42.913922: Epoch 54 
2025-06-12 10:04:42.914242: Current learning rate: 0.00951 
2025-06-12 10:05:23.164400: train_loss -0.602 
2025-06-12 10:05:23.164582: val_loss -0.4933 
2025-06-12 10:05:23.164640: Pseudo dice [np.float32(0.6249)] 
2025-06-12 10:05:23.164703: Epoch time: 40.25 s 
2025-06-12 10:05:24.211974:  
2025-06-12 10:05:24.212098: Epoch 55 
2025-06-12 10:05:24.212550: Current learning rate: 0.0095 
2025-06-12 10:06:04.601133: train_loss -0.615 
2025-06-12 10:06:04.601634: val_loss -0.5074 
2025-06-12 10:06:04.601872: Pseudo dice [np.float32(0.6351)] 
2025-06-12 10:06:04.602057: Epoch time: 40.39 s 
2025-06-12 10:06:04.602254: Yayy! New best EMA pseudo Dice: 0.6190999746322632 
2025-06-12 10:06:06.427608:  
2025-06-12 10:06:06.427740: Epoch 56 
2025-06-12 10:06:06.427843: Current learning rate: 0.00949 
2025-06-12 10:06:46.761494: train_loss -0.6191 
2025-06-12 10:06:46.761867: val_loss -0.4978 
2025-06-12 10:06:46.761933: Pseudo dice [np.float32(0.6232)] 
2025-06-12 10:06:46.762011: Epoch time: 40.34 s 
2025-06-12 10:06:46.762060: Yayy! New best EMA pseudo Dice: 0.6194999814033508 
2025-06-12 10:06:48.699511:  
2025-06-12 10:06:48.699840: Epoch 57 
2025-06-12 10:06:48.700097: Current learning rate: 0.00949 
2025-06-12 10:07:29.111639: train_loss -0.6201 
2025-06-12 10:07:29.111846: val_loss -0.4981 
2025-06-12 10:07:29.111941: Pseudo dice [np.float32(0.6136)] 
2025-06-12 10:07:29.112020: Epoch time: 40.41 s 
2025-06-12 10:07:30.153890:  
2025-06-12 10:07:30.154620: Epoch 58 
2025-06-12 10:07:30.154729: Current learning rate: 0.00948 
2025-06-12 10:08:10.410018: train_loss -0.6193 
2025-06-12 10:08:10.410293: val_loss -0.473 
2025-06-12 10:08:10.410368: Pseudo dice [np.float32(0.6122)] 
2025-06-12 10:08:10.410439: Epoch time: 40.26 s 
2025-06-12 10:08:11.469314:  
2025-06-12 10:08:11.469433: Epoch 59 
2025-06-12 10:08:11.469510: Current learning rate: 0.00947 
2025-06-12 10:08:51.737970: train_loss -0.6218 
2025-06-12 10:08:51.738232: val_loss -0.5156 
2025-06-12 10:08:51.738349: Pseudo dice [np.float32(0.6329)] 
2025-06-12 10:08:51.738466: Epoch time: 40.27 s 
2025-06-12 10:08:51.738541: Yayy! New best EMA pseudo Dice: 0.619700014591217 
2025-06-12 10:08:53.164347:  
2025-06-12 10:08:53.164604: Epoch 60 
2025-06-12 10:08:53.164771: Current learning rate: 0.00946 
2025-06-12 10:09:33.418927: train_loss -0.6208 
2025-06-12 10:09:33.419342: val_loss -0.4993 
2025-06-12 10:09:33.419529: Pseudo dice [np.float32(0.6184)] 
2025-06-12 10:09:33.419650: Epoch time: 40.26 s 
2025-06-12 10:09:34.474821:  
2025-06-12 10:09:34.474965: Epoch 61 
2025-06-12 10:09:34.475216: Current learning rate: 0.00945 
2025-06-12 10:10:14.827998: train_loss -0.6135 
2025-06-12 10:10:14.828335: val_loss -0.4969 
2025-06-12 10:10:14.828596: Pseudo dice [np.float32(0.6302)] 
2025-06-12 10:10:14.828693: Epoch time: 40.35 s 
2025-06-12 10:10:14.828763: Yayy! New best EMA pseudo Dice: 0.6205999851226807 
2025-06-12 10:10:16.710240:  
2025-06-12 10:10:16.710499: Epoch 62 
2025-06-12 10:10:16.710639: Current learning rate: 0.00944 
2025-06-12 10:10:56.947350: train_loss -0.6211 
2025-06-12 10:10:56.947562: val_loss -0.4783 
2025-06-12 10:10:56.947627: Pseudo dice [np.float32(0.6177)] 
2025-06-12 10:10:56.947718: Epoch time: 40.24 s 
2025-06-12 10:10:58.013169:  
2025-06-12 10:10:58.013309: Epoch 63 
2025-06-12 10:10:58.013513: Current learning rate: 0.00943 
2025-06-12 10:11:38.270048: train_loss -0.6246 
2025-06-12 10:11:38.270463: val_loss -0.5034 
2025-06-12 10:11:38.270695: Pseudo dice [np.float32(0.6255)] 
2025-06-12 10:11:38.270814: Epoch time: 40.26 s 
2025-06-12 10:11:38.270983: Yayy! New best EMA pseudo Dice: 0.6208999752998352 
2025-06-12 10:11:39.741778:  
2025-06-12 10:11:39.741921: Epoch 64 
2025-06-12 10:11:39.742006: Current learning rate: 0.00942 
2025-06-12 10:12:20.005389: train_loss -0.6255 
2025-06-12 10:12:20.005623: val_loss -0.5023 
2025-06-12 10:12:20.005692: Pseudo dice [np.float32(0.6225)] 
2025-06-12 10:12:20.005769: Epoch time: 40.26 s 
2025-06-12 10:12:20.005815: Yayy! New best EMA pseudo Dice: 0.6209999918937683 
2025-06-12 10:12:21.963364:  
2025-06-12 10:12:21.963665: Epoch 65 
2025-06-12 10:12:21.963978: Current learning rate: 0.00941 
2025-06-12 10:13:02.280430: train_loss -0.6338 
2025-06-12 10:13:02.280746: val_loss -0.4919 
2025-06-12 10:13:02.280838: Pseudo dice [np.float32(0.6152)] 
2025-06-12 10:13:02.280927: Epoch time: 40.32 s 
2025-06-12 10:13:03.367358:  
2025-06-12 10:13:03.367588: Epoch 66 
2025-06-12 10:13:03.367802: Current learning rate: 0.0094 
2025-06-12 10:13:43.819307: train_loss -0.6355 
2025-06-12 10:13:43.819551: val_loss -0.4853 
2025-06-12 10:13:43.819811: Pseudo dice [np.float32(0.6083)] 
2025-06-12 10:13:43.819932: Epoch time: 40.45 s 
2025-06-12 10:13:45.227334:  
2025-06-12 10:13:45.227614: Epoch 67 
2025-06-12 10:13:45.228084: Current learning rate: 0.00939 
2025-06-12 10:14:25.529818: train_loss -0.6299 
2025-06-12 10:14:25.530016: val_loss -0.4848 
2025-06-12 10:14:25.530092: Pseudo dice [np.float32(0.6197)] 
2025-06-12 10:14:25.530158: Epoch time: 40.3 s 
2025-06-12 10:14:26.592762:  
2025-06-12 10:14:26.593025: Epoch 68 
2025-06-12 10:14:26.593113: Current learning rate: 0.00939 
2025-06-12 10:15:06.866113: train_loss -0.6347 
2025-06-12 10:15:06.866449: val_loss -0.5076 
2025-06-12 10:15:06.866529: Pseudo dice [np.float32(0.6268)] 
2025-06-12 10:15:06.866609: Epoch time: 40.27 s 
2025-06-12 10:15:07.938168:  
2025-06-12 10:15:07.938451: Epoch 69 
2025-06-12 10:15:07.938626: Current learning rate: 0.00938 
2025-06-12 10:15:48.216421: train_loss -0.6396 
2025-06-12 10:15:48.216666: val_loss -0.4977 
2025-06-12 10:15:48.216731: Pseudo dice [np.float32(0.609)] 
2025-06-12 10:15:48.216800: Epoch time: 40.28 s 
2025-06-12 10:15:49.290891:  
2025-06-12 10:15:49.291010: Epoch 70 
2025-06-12 10:15:49.291220: Current learning rate: 0.00937 
2025-06-12 10:16:29.562529: train_loss -0.6255 
2025-06-12 10:16:29.562977: val_loss -0.5085 
2025-06-12 10:16:29.563166: Pseudo dice [np.float32(0.6368)] 
2025-06-12 10:16:29.563515: Epoch time: 40.27 s 
2025-06-12 10:16:30.677000:  
2025-06-12 10:16:30.677254: Epoch 71 
2025-06-12 10:16:30.677429: Current learning rate: 0.00936 
2025-06-12 10:17:11.015521: train_loss -0.6492 
2025-06-12 10:17:11.015749: val_loss -0.4792 
2025-06-12 10:17:11.015812: Pseudo dice [np.float32(0.6269)] 
2025-06-12 10:17:11.015887: Epoch time: 40.34 s 
2025-06-12 10:17:11.015957: Yayy! New best EMA pseudo Dice: 0.6212999820709229 
2025-06-12 10:17:12.492827:  
2025-06-12 10:17:12.493183: Epoch 72 
2025-06-12 10:17:12.493512: Current learning rate: 0.00935 
2025-06-12 10:17:52.737661: train_loss -0.6498 
2025-06-12 10:17:52.737845: val_loss -0.465 
2025-06-12 10:17:52.737915: Pseudo dice [np.float32(0.6072)] 
2025-06-12 10:17:52.738091: Epoch time: 40.25 s 
2025-06-12 10:17:53.803812:  
2025-06-12 10:17:53.804058: Epoch 73 
2025-06-12 10:17:53.804165: Current learning rate: 0.00934 
2025-06-12 10:18:34.118911: train_loss -0.6509 
2025-06-12 10:18:34.119144: val_loss -0.4938 
2025-06-12 10:18:34.119252: Pseudo dice [np.float32(0.6234)] 
2025-06-12 10:18:34.119461: Epoch time: 40.32 s 
2025-06-12 10:18:35.215574:  
2025-06-12 10:18:35.215780: Epoch 74 
2025-06-12 10:18:35.215907: Current learning rate: 0.00933 
2025-06-12 10:19:15.452801: train_loss -0.6588 
2025-06-12 10:19:15.453140: val_loss -0.4971 
2025-06-12 10:19:15.453223: Pseudo dice [np.float32(0.6274)] 
2025-06-12 10:19:15.453321: Epoch time: 40.24 s 
2025-06-12 10:19:16.556872:  
2025-06-12 10:19:16.557611: Epoch 75 
2025-06-12 10:19:16.557747: Current learning rate: 0.00932 
2025-06-12 10:19:56.845889: train_loss -0.6617 
2025-06-12 10:19:56.846110: val_loss -0.4854 
2025-06-12 10:19:56.846182: Pseudo dice [np.float32(0.6171)] 
2025-06-12 10:19:56.846276: Epoch time: 40.29 s 
2025-06-12 10:19:57.921598:  
2025-06-12 10:19:57.921744: Epoch 76 
2025-06-12 10:19:57.921826: Current learning rate: 0.00931 
2025-06-12 10:20:38.201770: train_loss -0.6512 
2025-06-12 10:20:38.201983: val_loss -0.4797 
2025-06-12 10:20:38.202048: Pseudo dice [np.float32(0.6013)] 
2025-06-12 10:20:38.202111: Epoch time: 40.28 s 
2025-06-12 10:20:39.284756:  
2025-06-12 10:20:39.284983: Epoch 77 
2025-06-12 10:20:39.285181: Current learning rate: 0.0093 
2025-06-12 10:21:19.580427: train_loss -0.664 
2025-06-12 10:21:19.580787: val_loss -0.4706 
2025-06-12 10:21:19.580972: Pseudo dice [np.float32(0.6033)] 
2025-06-12 10:21:19.581131: Epoch time: 40.3 s 
2025-06-12 10:21:20.994816:  
2025-06-12 10:21:20.995026: Epoch 78 
2025-06-12 10:21:20.995181: Current learning rate: 0.0093 
2025-06-12 10:22:01.389427: train_loss -0.6704 
2025-06-12 10:22:01.389710: val_loss -0.4798 
2025-06-12 10:22:01.389775: Pseudo dice [np.float32(0.6098)] 
2025-06-12 10:22:01.389843: Epoch time: 40.4 s 
2025-06-12 10:22:02.498646:  
2025-06-12 10:22:02.499077: Epoch 79 
2025-06-12 10:22:02.499252: Current learning rate: 0.00929 
2025-06-12 10:22:42.882226: train_loss -0.6639 
2025-06-12 10:22:42.882515: val_loss -0.5008 
2025-06-12 10:22:42.882601: Pseudo dice [np.float32(0.6233)] 
2025-06-12 10:22:42.882671: Epoch time: 40.38 s 
2025-06-12 10:22:43.965131:  
2025-06-12 10:22:43.965253: Epoch 80 
2025-06-12 10:22:43.965328: Current learning rate: 0.00928 
2025-06-12 10:23:24.308677: train_loss -0.6551 
2025-06-12 10:23:24.308870: val_loss -0.4774 
2025-06-12 10:23:24.308938: Pseudo dice [np.float32(0.6083)] 
2025-06-12 10:23:24.309002: Epoch time: 40.34 s 
2025-06-12 10:23:25.390684:  
2025-06-12 10:23:25.390945: Epoch 81 
2025-06-12 10:23:25.391057: Current learning rate: 0.00927 
2025-06-12 10:24:05.819590: train_loss -0.6334 
2025-06-12 10:24:05.819983: val_loss -0.5043 
2025-06-12 10:24:05.820295: Pseudo dice [np.float32(0.6328)] 
2025-06-12 10:24:05.820518: Epoch time: 40.43 s 
2025-06-12 10:24:06.908655:  
2025-06-12 10:24:06.908867: Epoch 82 
2025-06-12 10:24:06.909093: Current learning rate: 0.00926 
2025-06-12 10:24:47.244028: train_loss -0.6609 
2025-06-12 10:24:47.244356: val_loss -0.5088 
2025-06-12 10:24:47.244422: Pseudo dice [np.float32(0.6263)] 
2025-06-12 10:24:47.244510: Epoch time: 40.34 s 
2025-06-12 10:24:48.316004:  
2025-06-12 10:24:48.316302: Epoch 83 
2025-06-12 10:24:48.316547: Current learning rate: 0.00925 
2025-06-12 10:25:28.693110: train_loss -0.6491 
2025-06-12 10:25:28.693359: val_loss -0.5311 
2025-06-12 10:25:28.693437: Pseudo dice [np.float32(0.6461)] 
2025-06-12 10:25:28.693518: Epoch time: 40.38 s 
2025-06-12 10:25:28.693578: Yayy! New best EMA pseudo Dice: 0.621399998664856 
2025-06-12 10:25:30.651691:  
2025-06-12 10:25:30.652110: Epoch 84 
2025-06-12 10:25:30.652248: Current learning rate: 0.00924 
2025-06-12 10:26:10.964624: train_loss -0.6469 
2025-06-12 10:26:10.964913: val_loss -0.4892 
2025-06-12 10:26:10.964990: Pseudo dice [np.float32(0.6243)] 
2025-06-12 10:26:10.965070: Epoch time: 40.31 s 
2025-06-12 10:26:10.965132: Yayy! New best EMA pseudo Dice: 0.6216999888420105 
2025-06-12 10:26:12.523811:  
2025-06-12 10:26:12.524042: Epoch 85 
2025-06-12 10:26:12.524459: Current learning rate: 0.00923 
2025-06-12 10:26:52.800002: train_loss -0.6655 
2025-06-12 10:26:52.800354: val_loss -0.4922 
2025-06-12 10:26:52.800429: Pseudo dice [np.float32(0.6115)] 
2025-06-12 10:26:52.800497: Epoch time: 40.28 s 
2025-06-12 10:26:53.866174:  
2025-06-12 10:26:53.866373: Epoch 86 
2025-06-12 10:26:53.866490: Current learning rate: 0.00922 
2025-06-12 10:27:34.190712: train_loss -0.6596 
2025-06-12 10:27:34.191026: val_loss -0.4972 
2025-06-12 10:27:34.191108: Pseudo dice [np.float32(0.6234)] 
2025-06-12 10:27:34.191175: Epoch time: 40.33 s 
2025-06-12 10:27:35.255407:  
2025-06-12 10:27:35.255550: Epoch 87 
2025-06-12 10:27:35.255856: Current learning rate: 0.00921 
2025-06-12 10:28:15.692883: train_loss -0.6603 
2025-06-12 10:28:15.693178: val_loss -0.5128 
2025-06-12 10:28:15.693275: Pseudo dice [np.float32(0.6464)] 
2025-06-12 10:28:15.693385: Epoch time: 40.44 s 
2025-06-12 10:28:15.693457: Yayy! New best EMA pseudo Dice: 0.6234999895095825 
2025-06-12 10:28:17.647525:  
2025-06-12 10:28:17.647873: Epoch 88 
2025-06-12 10:28:17.648192: Current learning rate: 0.0092 
2025-06-12 10:28:57.955650: train_loss -0.6629 
2025-06-12 10:28:57.955847: val_loss -0.5021 
2025-06-12 10:28:57.955906: Pseudo dice [np.float32(0.6373)] 
2025-06-12 10:28:57.955971: Epoch time: 40.31 s 
2025-06-12 10:28:57.956039: Yayy! New best EMA pseudo Dice: 0.6248999834060669 
2025-06-12 10:28:59.984779:  
2025-06-12 10:28:59.985183: Epoch 89 
2025-06-12 10:28:59.985557: Current learning rate: 0.0092 
2025-06-12 10:29:40.410694: train_loss -0.6571 
2025-06-12 10:29:40.411044: val_loss -0.4973 
2025-06-12 10:29:40.411172: Pseudo dice [np.float32(0.6227)] 
2025-06-12 10:29:40.411299: Epoch time: 40.43 s 
2025-06-12 10:29:41.472682:  
2025-06-12 10:29:41.472827: Epoch 90 
2025-06-12 10:29:41.472950: Current learning rate: 0.00919 
2025-06-12 10:30:21.870000: train_loss -0.6635 
2025-06-12 10:30:21.870393: val_loss -0.4994 
2025-06-12 10:30:21.870601: Pseudo dice [np.float32(0.6193)] 
2025-06-12 10:30:21.870699: Epoch time: 40.4 s 
2025-06-12 10:30:22.956604:  
2025-06-12 10:30:22.956823: Epoch 91 
2025-06-12 10:30:22.957132: Current learning rate: 0.00918 
2025-06-12 10:31:03.284400: train_loss -0.6798 
2025-06-12 10:31:03.284680: val_loss -0.526 
2025-06-12 10:31:03.284762: Pseudo dice [np.float32(0.6431)] 
2025-06-12 10:31:03.284847: Epoch time: 40.33 s 
2025-06-12 10:31:03.284904: Yayy! New best EMA pseudo Dice: 0.6259999871253967 
2025-06-12 10:31:05.219160:  
2025-06-12 10:31:05.219681: Epoch 92 
2025-06-12 10:31:05.220033: Current learning rate: 0.00917 
2025-06-12 10:31:45.577251: train_loss -0.6631 
2025-06-12 10:31:45.577473: val_loss -0.5044 
2025-06-12 10:31:45.577547: Pseudo dice [np.float32(0.6267)] 
2025-06-12 10:31:45.577645: Epoch time: 40.36 s 
2025-06-12 10:31:45.577710: Yayy! New best EMA pseudo Dice: 0.6261000037193298 
2025-06-12 10:31:47.108781:  
2025-06-12 10:31:47.109025: Epoch 93 
2025-06-12 10:31:47.109142: Current learning rate: 0.00916 
2025-06-12 10:32:27.457548: train_loss -0.678 
2025-06-12 10:32:27.457858: val_loss -0.4941 
2025-06-12 10:32:27.457934: Pseudo dice [np.float32(0.6237)] 
2025-06-12 10:32:27.458006: Epoch time: 40.35 s 
2025-06-12 10:32:28.529063:  
2025-06-12 10:32:28.529345: Epoch 94 
2025-06-12 10:32:28.529543: Current learning rate: 0.00915 
2025-06-12 10:33:08.904715: train_loss -0.688 
2025-06-12 10:33:08.904943: val_loss -0.5147 
2025-06-12 10:33:08.905009: Pseudo dice [np.float32(0.6465)] 
2025-06-12 10:33:08.905101: Epoch time: 40.38 s 
2025-06-12 10:33:08.905163: Yayy! New best EMA pseudo Dice: 0.6279000043869019 
2025-06-12 10:33:10.791874:  
2025-06-12 10:33:10.792121: Epoch 95 
2025-06-12 10:33:10.792255: Current learning rate: 0.00914 
2025-06-12 10:33:51.059880: train_loss -0.6779 
2025-06-12 10:33:51.060403: val_loss -0.5099 
2025-06-12 10:33:51.060638: Pseudo dice [np.float32(0.6325)] 
2025-06-12 10:33:51.060711: Epoch time: 40.27 s 
2025-06-12 10:33:51.060766: Yayy! New best EMA pseudo Dice: 0.6284000277519226 
2025-06-12 10:33:52.493573:  
2025-06-12 10:33:52.493913: Epoch 96 
2025-06-12 10:33:52.494092: Current learning rate: 0.00913 
2025-06-12 10:34:32.857958: train_loss -0.6856 
2025-06-12 10:34:32.858351: val_loss -0.5085 
2025-06-12 10:34:32.858456: Pseudo dice [np.float32(0.617)] 
2025-06-12 10:34:32.858541: Epoch time: 40.37 s 
2025-06-12 10:34:33.895362:  
2025-06-12 10:34:33.895503: Epoch 97 
2025-06-12 10:34:33.895595: Current learning rate: 0.00912 
2025-06-12 10:35:14.122724: train_loss -0.6899 
2025-06-12 10:35:14.123000: val_loss -0.4908 
2025-06-12 10:35:14.123297: Pseudo dice [np.float32(0.6112)] 
2025-06-12 10:35:14.123398: Epoch time: 40.23 s 
2025-06-12 10:35:15.157036:  
2025-06-12 10:35:15.157231: Epoch 98 
2025-06-12 10:35:15.157391: Current learning rate: 0.00911 
2025-06-12 10:35:55.380635: train_loss -0.6962 
2025-06-12 10:35:55.380944: val_loss -0.4972 
2025-06-12 10:35:55.381009: Pseudo dice [np.float32(0.6321)] 
2025-06-12 10:35:55.381074: Epoch time: 40.22 s 
2025-06-12 10:35:56.427950:  
2025-06-12 10:35:56.428069: Epoch 99 
2025-06-12 10:35:56.428146: Current learning rate: 0.0091 
2025-06-12 10:36:36.729062: train_loss -0.6909 
2025-06-12 10:36:36.729922: val_loss -0.5114 
2025-06-12 10:36:36.730006: Pseudo dice [np.float32(0.6202)] 
2025-06-12 10:36:36.730070: Epoch time: 40.3 s 
2025-06-12 10:36:38.623939:  
2025-06-12 10:36:38.624349: Epoch 100 
2025-06-12 10:36:38.624462: Current learning rate: 0.0091 
2025-06-12 10:37:18.892695: train_loss -0.6959 
2025-06-12 10:37:18.892925: val_loss -0.4773 
2025-06-12 10:37:18.892988: Pseudo dice [np.float32(0.6055)] 
2025-06-12 10:37:18.893052: Epoch time: 40.27 s 
2025-06-12 10:37:20.302675:  
2025-06-12 10:37:20.302901: Epoch 101 
2025-06-12 10:37:20.303004: Current learning rate: 0.00909 
2025-06-12 10:38:00.563811: train_loss -0.7007 
2025-06-12 10:38:00.564091: val_loss -0.5028 
2025-06-12 10:38:00.564265: Pseudo dice [np.float32(0.6299)] 
2025-06-12 10:38:00.564437: Epoch time: 40.26 s 
2025-06-12 10:38:01.589706:  
2025-06-12 10:38:01.589849: Epoch 102 
2025-06-12 10:38:01.589938: Current learning rate: 0.00908 
2025-06-12 10:38:41.849267: train_loss -0.6779 
2025-06-12 10:38:41.849660: val_loss -0.4914 
2025-06-12 10:38:41.849852: Pseudo dice [np.float32(0.6151)] 
2025-06-12 10:38:41.849966: Epoch time: 40.26 s 
2025-06-12 10:38:42.884054:  
2025-06-12 10:38:42.884212: Epoch 103 
2025-06-12 10:38:42.884303: Current learning rate: 0.00907 
2025-06-12 10:39:23.105801: train_loss -0.6815 
2025-06-12 10:39:23.105979: val_loss -0.4853 
2025-06-12 10:39:23.106059: Pseudo dice [np.float32(0.6167)] 
2025-06-12 10:39:23.106125: Epoch time: 40.22 s 
2025-06-12 10:39:24.138664:  
2025-06-12 10:39:24.138901: Epoch 104 
2025-06-12 10:39:24.139010: Current learning rate: 0.00906 
2025-06-12 10:40:04.369692: train_loss -0.6785 
2025-06-12 10:40:04.370069: val_loss -0.4848 
2025-06-12 10:40:04.370301: Pseudo dice [np.float32(0.6073)] 
2025-06-12 10:40:04.370428: Epoch time: 40.23 s 
2025-06-12 10:40:05.409178:  
2025-06-12 10:40:05.409546: Epoch 105 
2025-06-12 10:40:05.409739: Current learning rate: 0.00905 
2025-06-12 10:40:45.660243: train_loss -0.6984 
2025-06-12 10:40:45.660462: val_loss -0.4766 
2025-06-12 10:40:45.660525: Pseudo dice [np.float32(0.6068)] 
2025-06-12 10:40:45.660589: Epoch time: 40.25 s 
2025-06-12 10:40:46.690722:  
2025-06-12 10:40:46.690837: Epoch 106 
2025-06-12 10:40:46.690929: Current learning rate: 0.00904 
2025-06-12 10:41:27.003527: train_loss -0.6931 
2025-06-12 10:41:27.003721: val_loss -0.5105 
2025-06-12 10:41:27.003934: Pseudo dice [np.float32(0.637)] 
2025-06-12 10:41:27.004055: Epoch time: 40.31 s 
2025-06-12 10:41:28.033716:  
2025-06-12 10:41:28.033955: Epoch 107 
2025-06-12 10:41:28.034082: Current learning rate: 0.00903 
2025-06-12 10:42:08.310974: train_loss -0.6724 
2025-06-12 10:42:08.311165: val_loss -0.4916 
2025-06-12 10:42:08.311422: Pseudo dice [np.float32(0.6153)] 
2025-06-12 10:42:08.311566: Epoch time: 40.28 s 
2025-06-12 10:42:09.356117:  
2025-06-12 10:42:09.356256: Epoch 108 
2025-06-12 10:42:09.356348: Current learning rate: 0.00902 
2025-06-12 10:42:49.628615: train_loss -0.698 
2025-06-12 10:42:49.628770: val_loss -0.4841 
2025-06-12 10:42:49.628827: Pseudo dice [np.float32(0.6191)] 
2025-06-12 10:42:49.628891: Epoch time: 40.27 s 
2025-06-12 10:42:50.672809:  
2025-06-12 10:42:50.673116: Epoch 109 
2025-06-12 10:42:50.673557: Current learning rate: 0.00901 
2025-06-12 10:43:31.010860: train_loss -0.7065 
2025-06-12 10:43:31.011171: val_loss -0.4945 
2025-06-12 10:43:31.011276: Pseudo dice [np.float32(0.6189)] 
2025-06-12 10:43:31.011408: Epoch time: 40.34 s 
2025-06-12 10:43:32.046850:  
2025-06-12 10:43:32.047141: Epoch 110 
2025-06-12 10:43:32.047362: Current learning rate: 0.009 
2025-06-12 10:44:12.329418: train_loss -0.7017 
2025-06-12 10:44:12.329621: val_loss -0.5036 
2025-06-12 10:44:12.329684: Pseudo dice [np.float32(0.6365)] 
2025-06-12 10:44:12.329750: Epoch time: 40.28 s 
2025-06-12 10:44:13.375477:  
2025-06-12 10:44:13.375600: Epoch 111 
2025-06-12 10:44:13.375792: Current learning rate: 0.009 
2025-06-12 10:44:53.790188: train_loss -0.7117 
2025-06-12 10:44:53.790493: val_loss -0.5161 
2025-06-12 10:44:53.790737: Pseudo dice [np.float32(0.6338)] 
2025-06-12 10:44:53.790819: Epoch time: 40.42 s 
2025-06-12 10:44:54.835850:  
2025-06-12 10:44:54.836030: Epoch 112 
2025-06-12 10:44:54.836144: Current learning rate: 0.00899 
2025-06-12 10:45:35.136785: train_loss -0.7143 
2025-06-12 10:45:35.137236: val_loss -0.491 
2025-06-12 10:45:35.137313: Pseudo dice [np.float32(0.6162)] 
2025-06-12 10:45:35.137408: Epoch time: 40.3 s 
2025-06-12 10:45:36.508825:  
2025-06-12 10:45:36.509104: Epoch 113 
2025-06-12 10:45:36.509474: Current learning rate: 0.00898 
2025-06-12 10:46:16.866182: train_loss -0.7173 
2025-06-12 10:46:16.866417: val_loss -0.4911 
2025-06-12 10:46:16.866501: Pseudo dice [np.float32(0.6271)] 
2025-06-12 10:46:16.866637: Epoch time: 40.36 s 
2025-06-12 10:46:17.928774:  
2025-06-12 10:46:17.929096: Epoch 114 
2025-06-12 10:46:17.929346: Current learning rate: 0.00897 
2025-06-12 10:46:58.332594: train_loss -0.7188 
2025-06-12 10:46:58.332832: val_loss -0.5024 
2025-06-12 10:46:58.332984: Pseudo dice [np.float32(0.6335)] 
2025-06-12 10:46:58.333075: Epoch time: 40.41 s 
2025-06-12 10:46:59.375864:  
2025-06-12 10:46:59.376046: Epoch 115 
2025-06-12 10:46:59.376132: Current learning rate: 0.00896 
2025-06-12 10:47:39.678834: train_loss -0.7074 
2025-06-12 10:47:39.679064: val_loss -0.4754 
2025-06-12 10:47:39.679136: Pseudo dice [np.float32(0.6046)] 
2025-06-12 10:47:39.679223: Epoch time: 40.3 s 
2025-06-12 10:47:40.749814:  
2025-06-12 10:47:40.750180: Epoch 116 
2025-06-12 10:47:40.750298: Current learning rate: 0.00895 
2025-06-12 10:48:21.167269: train_loss -0.709 
2025-06-12 10:48:21.167630: val_loss -0.4939 
2025-06-12 10:48:21.167820: Pseudo dice [np.float32(0.6328)] 
2025-06-12 10:48:21.167917: Epoch time: 40.42 s 
2025-06-12 10:48:22.232681:  
2025-06-12 10:48:22.232907: Epoch 117 
2025-06-12 10:48:22.233056: Current learning rate: 0.00894 
2025-06-12 10:49:02.566305: train_loss -0.7045 
2025-06-12 10:49:02.566635: val_loss -0.4754 
2025-06-12 10:49:02.566717: Pseudo dice [np.float32(0.6079)] 
2025-06-12 10:49:02.566787: Epoch time: 40.33 s 
2025-06-12 10:49:03.637508:  
2025-06-12 10:49:03.637685: Epoch 118 
2025-06-12 10:49:03.638064: Current learning rate: 0.00893 
2025-06-12 10:49:44.025358: train_loss -0.7123 
2025-06-12 10:49:44.025629: val_loss -0.4928 
2025-06-12 10:49:44.025695: Pseudo dice [np.float32(0.6177)] 
2025-06-12 10:49:44.025815: Epoch time: 40.39 s 
2025-06-12 10:49:45.098699:  
2025-06-12 10:49:45.099038: Epoch 119 
2025-06-12 10:49:45.099131: Current learning rate: 0.00892 
2025-06-12 10:50:25.511814: train_loss -0.7174 
2025-06-12 10:50:25.512033: val_loss -0.4905 
2025-06-12 10:50:25.512098: Pseudo dice [np.float32(0.6223)] 
2025-06-12 10:50:25.512170: Epoch time: 40.41 s 
2025-06-12 10:50:26.594048:  
2025-06-12 10:50:26.594683: Epoch 120 
2025-06-12 10:50:26.595083: Current learning rate: 0.00891 
2025-06-12 10:51:06.975193: train_loss -0.722 
2025-06-12 10:51:06.975556: val_loss -0.5162 
2025-06-12 10:51:06.975641: Pseudo dice [np.float32(0.6261)] 
2025-06-12 10:51:06.975734: Epoch time: 40.38 s 
2025-06-12 10:51:08.058415:  
2025-06-12 10:51:08.058556: Epoch 121 
2025-06-12 10:51:08.058730: Current learning rate: 0.0089 
